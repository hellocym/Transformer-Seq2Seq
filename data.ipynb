{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4pdvGPU Msg(31121:140200917776192:libvgpu.c:870)]: Initializing.....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "class PeptideDataset(Dataset):\n",
    "    def __init__(self, files, split='train', transform=None):\n",
    "        # 初始为空的列表，用于存储各个分割的数据\n",
    "        train_data_list = []\n",
    "        val_data_list = []\n",
    "        test_data_list = []\n",
    "\n",
    "        # 对每个文件单独进行划分\n",
    "        for file in files:\n",
    "            # 读取文件\n",
    "            data = pd.read_csv(file, header=None, skiprows=1)\n",
    "            # 取第一列和第二列数据\n",
    "            data = data.iloc[:, :2]\n",
    "            \n",
    "            # 划分数据\n",
    "            train_temp, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "            val_temp, test_temp = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "            \n",
    "            # 追加到相应的列表中\n",
    "            train_data_list.append(train_temp)\n",
    "            val_data_list.append(val_temp)\n",
    "            test_data_list.append(test_temp)\n",
    "\n",
    "        # 合并来自所有文件的数据\n",
    "        if split == 'train':\n",
    "            self.data = pd.concat(train_data_list, ignore_index=True)\n",
    "        elif split == 'val':\n",
    "            self.data = pd.concat(val_data_list, ignore_index=True)\n",
    "        elif split == 'test':\n",
    "            self.data = pd.concat(test_data_list, ignore_index=True)\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        column1 = row[0]\n",
    "        column2 = row[1]\n",
    "        if self.transform:\n",
    "            column1 = self.transform(column1)\n",
    "            column2 = self.transform(column2)\n",
    "        return (column1, column2)\n",
    "\n",
    "# 用于字符到整数的映射\n",
    "def text_transform(text):\n",
    "    bos_token = 2\n",
    "    # 首先将文本转换为字符的ascii值列表\n",
    "    transformed_text = [ord(char) for char in text]\n",
    "    return transformed_text\n",
    "\n",
    "# 创建数据集实例\n",
    "root = 'data'\n",
    "files = [os.path.join(root, f) for f in os.listdir(root) if f.endswith('csv')]\n",
    "train_dataset = PeptideDataset(files, split='train', transform=text_transform)\n",
    "val_dataset = PeptideDataset(files, split='val', transform=text_transform)\n",
    "test_dataset = PeptideDataset(files, split='test', transform=text_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([89,\n",
       "  72,\n",
       "  84,\n",
       "  69,\n",
       "  89,\n",
       "  82,\n",
       "  69,\n",
       "  73,\n",
       "  67,\n",
       "  65,\n",
       "  75,\n",
       "  84,\n",
       "  68,\n",
       "  69,\n",
       "  78,\n",
       "  73,\n",
       "  65,\n",
       "  89,\n",
       "  76,\n",
       "  78,\n",
       "  89,\n",
       "  72,\n",
       "  68,\n",
       "  89,\n",
       "  84,\n",
       "  87,\n",
       "  65,\n",
       "  86,\n",
       "  76,\n",
       "  65,\n",
       "  89,\n",
       "  69,\n",
       "  87,\n",
       "  89],\n",
       " [73,\n",
       "  78,\n",
       "  83,\n",
       "  81,\n",
       "  76,\n",
       "  69,\n",
       "  70,\n",
       "  75,\n",
       "  73,\n",
       "  75,\n",
       "  80,\n",
       "  70,\n",
       "  83,\n",
       "  76,\n",
       "  86,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  82,\n",
       "  87,\n",
       "  76,\n",
       "  86,\n",
       "  75,\n",
       "  82,\n",
       "  71])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    pad_token = 1\n",
    "    bos_token = 2\n",
    "    \n",
    "    # 处理batch中的每个样本，样本是(column1, column2)的形式\n",
    "    batch_column1 = [torch.tensor([bos_token] + item[0] + [3]) for item in batch]  # 对第一列应用转换\n",
    "    batch_column2 = [torch.tensor([bos_token] + item[1] + [3]) for item in batch]  # 对第二列应用转换\n",
    "    \n",
    "    # 对两列数据进行padding\n",
    "    column1_padded = pad_sequence([torch.tensor(x) for x in batch_column1], \n",
    "                            padding_value=pad_token, batch_first=True)\n",
    "    column2_padded = pad_sequence([torch.tensor(x) for x in batch_column2], \n",
    "                            padding_value=pad_token, batch_first=True)\n",
    "    \n",
    "    return column1_padded.T, column2_padded.T\n",
    "\n",
    "# 示例：使用collate_fn生成dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [89, 89, 89,  ..., 89, 89, 89],\n",
      "        [68, 89, 72,  ..., 72, 70, 89],\n",
      "        ...,\n",
      "        [87, 87, 87,  ..., 87, 87, 87],\n",
      "        [89, 72, 89,  ..., 89, 89, 89],\n",
      "        [ 3,  3,  3,  ...,  3,  3,  3]])\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [75, 77, 77, 82, 70, 69, 86, 87, 81, 69, 82, 84, 72, 65, 84, 86, 83, 82,\n",
      "         81, 77, 82, 75, 76, 69, 84, 80, 75, 83, 86, 76, 77, 70],\n",
      "        [70, 40, 82, 86, 83, 71, 76, 75, 76, 72, 73, 76, 76, 76, 87, 81, 80, 71,\n",
      "         68, 76, 76, 82, 84, 76, 80, 84, 77, 65, 73, 83, 81, 86],\n",
      "        [69, 43, 76, 70, 78, 71, 86, 82, 75, 83, 83, 87, 83, 82, 70, 87, 76, 80,\n",
      "         67, 80, 75, 77, 80, 77, 82, 82, 69, 70, 81, 83, 77, 69],\n",
      "        [69, 49, 80, 69, 75, 86, 65, 76, 81, 78, 72, 69, 71, 65, 65, 71, 83, 80,\n",
      "         70, 86, 71, 65, 75, 86, 83, 87, 76, 71, 76, 78, 78, 87],\n",
      "        [81, 53, 80, 86, 73, 83, 76, 73, 87, 71, 87, 81, 76, 86, 78, 76, 83, 72,\n",
      "         68, 81, 84, 81, 86, 76, 72, 86, 84, 65, 84, 65, 72, 76],\n",
      "        [78, 46, 82, 89, 83, 84, 75, 73, 69, 84, 84, 86, 81, 84, 65, 69, 80, 83,\n",
      "         76, 80, 65, 81, 84, 80, 76, 65, 84, 71, 65, 71, 73, 77],\n",
      "        [82, 57, 65, 72, 78, 69, 82, 76, 69, 86, 65, 71, 82, 76, 82, 82, 76, 68,\n",
      "         81, 65, 65, 86, 70, 65, 75, 80, 84, 70, 84, 71, 81, 68],\n",
      "        [65, 57, 71, 84, 70, 84, 65, 75, 71, 65, 84, 76, 72, 84, 82, 65, 65, 83,\n",
      "         84, 69, 86, 75, 67, 86, 69, 82, 69, 67, 80, 86, 65, 84],\n",
      "        [69, 41, 86, 84, 76, 69, 81,  3, 83, 80, 75, 89, 70, 65, 82, 80, 81, 67,\n",
      "         72, 76, 75, 89, 76, 65, 65, 78, 81, 84, 86, 80, 76, 86],\n",
      "        [83, 80,  3, 86, 76, 75, 83,  1, 71, 68, 65, 76,  3, 75, 76, 89, 65, 80,\n",
      "         86,  3, 75,  3,  3, 65,  3, 82, 76, 84, 83, 81,  3,  3],\n",
      "        [69, 78,  1, 76, 70, 80, 69,  1, 77, 83, 86,  3,  1,  3, 75,  3,  3, 71,\n",
      "         76,  1,  3,  1,  1, 80,  1, 71,  3, 86, 65, 76,  1,  1],\n",
      "        [67, 84,  1, 75, 73, 75, 76,  1, 84, 80, 65,  1,  1,  1, 75,  1,  1, 76,\n",
      "          3,  1,  1,  1,  1, 65,  1, 83,  1, 73, 76,  3,  1,  1],\n",
      "        [76, 82,  1,  3, 76, 75, 86,  1, 65, 84, 86,  1,  1,  1, 71,  1,  1, 80,\n",
      "          1,  1,  1,  1,  1, 77,  1, 69,  1, 84, 86,  1,  1,  1],\n",
      "        [68, 76,  1,  1, 86, 75, 65,  1, 73, 83,  3,  1,  1,  1, 78,  1,  1, 76,\n",
      "          1,  1,  1,  1,  1, 86,  1, 70,  1, 83, 68,  1,  1,  1],\n",
      "        [71, 80,  1,  1, 86, 70, 72,  1, 82, 80,  1,  1,  1,  1, 75,  1,  1, 72,\n",
      "          1,  1,  1,  1,  1, 65,  1, 71,  1, 80, 69,  1,  1,  1],\n",
      "        [ 3, 76,  1,  1, 83, 75, 81,  1, 75, 65,  1,  1,  1,  1, 86,  1,  1, 82,\n",
      "          1,  1,  1,  1,  1, 73,  1, 72,  1, 86, 80,  1,  1,  1],\n",
      "        [ 1, 80,  1,  1, 70, 69, 75,  1, 73, 83,  1,  1,  1,  1, 84,  1,  1, 76,\n",
      "          1,  1,  1,  1,  1, 80,  1, 78,  1, 68, 86,  1,  1,  1],\n",
      "        [ 1,  3,  1,  1, 76, 75, 75,  1, 75, 68,  1,  1,  1,  1, 87,  1,  1, 82,\n",
      "          1,  1,  1,  1,  1, 71,  1, 71,  1, 86, 72,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 84, 78, 73,  1, 82, 71,  1,  1,  1,  1, 71,  1,  1, 73,\n",
      "          1,  1,  1,  1,  1, 80,  1, 86,  1, 86, 73,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 89, 75, 76,  1, 65, 80,  1,  1,  1,  1, 65,  1,  1, 80,\n",
      "          1,  1,  1,  1,  1, 65,  1, 68,  1, 75, 82,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 83, 78, 72,  1, 68, 65,  1,  1,  1,  1, 82,  1,  1, 68,\n",
      "          1,  1,  1,  1,  1, 71,  1, 71,  1, 84, 65,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 73, 83, 86,  1, 80, 76,  1,  1,  1,  1, 83,  1,  1, 70,\n",
      "          1,  1,  1,  1,  1, 83,  1, 78,  1, 82, 84,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 87, 68, 68,  1, 81, 80,  1,  1,  1,  1, 75,  1,  1, 67,\n",
      "          1,  1,  1,  1,  1, 65,  1, 71,  1, 89, 71,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 65, 71, 78,  1, 81, 83,  1,  1,  1,  1, 68,  1,  1, 80,\n",
      "          1,  1,  1,  1,  1, 65,  1, 86,  1, 77, 76,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1, 83, 71, 72,  1, 76, 80,  1,  1,  1,  1, 81,  1,  1, 80,\n",
      "          1,  1,  1,  1,  1, 76,  1, 71,  1, 78, 73,  1,  1,  1],\n",
      "        [ 1,  1,  1,  1,  3,  3,  3,  1,  3,  3,  1,  1,  1,  1,  3,  1,  1,  3,\n",
      "          1,  1,  1,  1,  1,  3,  1,  3,  1,  3,  3,  1,  1,  1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31121/1607180702.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  column1_padded = pad_sequence([torch.tensor(x) for x in batch_column1],\n",
      "/tmp/ipykernel_31121/1607180702.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  column2_padded = pad_sequence([torch.tensor(x) for x in batch_column2],\n"
     ]
    }
   ],
   "source": [
    "for src, tgt in train_loader:\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
